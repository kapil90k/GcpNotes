SET PYSPARK IN JUPYTER--->
  PYSPARK_DRIVER_PYTHON: jupyter
  PYSPARK_DRIVER_PYTHON_OPTS: 'notebook'
  PYTHONPATH: C:\Installations\spark-2.2.2-bin-hadoop2.7\python\lib\py4j-0.10.7-src.zip

SUBMITTING SPARK JOB ON DATAPROC--->
  gcloud dataproc jobs submit pyspark wordcount.py --cluster ultimate-task-257513 --region 'us-central1' --jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar
